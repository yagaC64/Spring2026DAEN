{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 30 Score Operational Indices\n\nStage: `03_scoring`\nDiscipline: index scoring and confidence integration.\n\nInputs:\n- `outputs/index_pipeline/10_features/municipio_exposure_vulnerability_features.csv`\n- `outputs/index_pipeline/20_features/municipio_hazard_features.csv`\n\nOutput:\n- `outputs/index_pipeline/30_scoring/municipio_indices_scored.csv`\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Setup\nimport importlib.util\nimport subprocess\nimport sys\nfrom pathlib import Path\nimport os\nimport logging\nimport numpy as np\n\n\ndef ensure_packages(packages):\n    missing = [p for p in packages if importlib.util.find_spec(p) is None]\n    if missing:\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", *missing])\n\n\nensure_packages([\"pandas\", \"numpy\"])\nimport pandas as pd\n\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\nlogger = logging.getLogger(\"index-pipeline-stage30\")\n\n\ndef find_repo_root():\n    p = Path.cwd().resolve()\n    for c in [p, *p.parents]:\n        if (c / \"JupyterNotebooks\").exists():\n            return c\n    return p\n\n\nREPO_ROOT = find_repo_root()\nBASE_OUT = REPO_ROOT / \"JupyterNotebooks\" / \"outputs\" / \"index_pipeline\"\nINPUT_10 = BASE_OUT / \"10_features\" / \"municipio_exposure_vulnerability_features.csv\"\nINPUT_20 = BASE_OUT / \"20_features\" / \"municipio_hazard_features.csv\"\nOUTPUT_DIR = BASE_OUT / \"30_scoring\"\nOUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n\ntry:\n    from IPython.display import display\nexcept ImportError:\n    display = print\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: Load and score\nfor f in [INPUT_10, INPUT_20]:\n    if not f.exists():\n        raise FileNotFoundError(f\"Missing dependency: {f}\")\n\nx_df = pd.read_csv(INPUT_10)\nh_df = pd.read_csv(INPUT_20)\ndf = x_df.merge(h_df, on=[\"municipio\", \"municipio_key\", \"latitude\", \"longitude\"], how=\"inner\")\n\nphase = os.environ.get(\"INDEX_PHASE\", \"DURING\").upper().strip()\nif phase not in {\"PRE\", \"DURING\", \"POST\"}:\n    phase = \"DURING\"\n\n# Base components\nhazard = pd.to_numeric(df[\"hazard_combined\"], errors=\"coerce\").fillna(0).clip(0, 100)\nexposure = pd.to_numeric(df[\"exposure_score\"], errors=\"coerce\").fillna(0).clip(0, 100)\nvulnerability = pd.to_numeric(df[\"vulnerability_score\"], errors=\"coerce\").fillna(0).clip(0, 100)\nresilience_base = pd.to_numeric(df[\"resilience_capacity_score\"], errors=\"coerce\").fillna(0).clip(0, 100)\n\n# Risk in multiplicative form (scaled 0-100)\ndf[\"risk_index_raw\"] = (hazard / 100.0) * (exposure / 100.0) * (vulnerability / 100.0) * 100.0\n\n# Operational indices (weighted sums)\ndf[\"resilience_index\"] = resilience_base\n\ndf[\"response_readiness_index\"] = (\n    0.45 * (100 - hazard)\n    + 0.35 * resilience_base\n    + 0.20 * (100 - vulnerability)\n).clip(0, 100)\n\ndf[\"recovery_capacity_index\"] = (\n    0.50 * resilience_base\n    + 0.25 * (100 - exposure)\n    + 0.25 * (100 - vulnerability)\n).clip(0, 100)\n\n# Phase-aware priority index\nphase_weights = {\n    \"PRE\": {\"risk\": 0.45, \"rr\": 0.35, \"rc\": 0.20},\n    \"DURING\": {\"risk\": 0.60, \"rr\": 0.30, \"rc\": 0.10},\n    \"POST\": {\"risk\": 0.35, \"rr\": 0.20, \"rc\": 0.45},\n}\nw = phase_weights[phase]\n\ndf[\"priority_index\"] = (\n    w[\"risk\"] * df[\"risk_index_raw\"]\n    + w[\"rr\"] * (100 - df[\"response_readiness_index\"])  # lower readiness => higher priority\n    + w[\"rc\"] * (100 - df[\"recovery_capacity_index\"])   # lower recovery capacity => higher priority\n).clip(0, 100)\n\n# Confidence score\nlatest_obs = pd.to_datetime(df.get(\"noaa_latest_obs_utc\"), utc=True, errors=\"coerce\")\nage_hours = (pd.Timestamp.now(tz=\"UTC\") - latest_obs).dt.total_seconds() / 3600.0\nfreshness = (100 - (age_hours.fillna(168).clip(0, 168) / 168) * 100).clip(0, 100)\ncompleteness = df[[\n    \"hazard_combined\", \"exposure_score\", \"vulnerability_score\", \"resilience_capacity_score\"\n]].notna().mean(axis=1) * 100\nvalidity = ((hazard.between(0, 100)) & (exposure.between(0, 100)) & (vulnerability.between(0, 100))).astype(float) * 100\ncrosscheck = np.where((df[\"flood_hazard_muni\"].fillna(0) > 0) | (df[\"earthquake_hazard_score\"].fillna(0) > 0), 85.0, 60.0)\n\ndf[\"confidence_score\"] = (0.35 * freshness + 0.25 * completeness + 0.25 * validity + 0.15 * crosscheck).clip(0, 100)\ndf[\"confidence_0_1\"] = (df[\"confidence_score\"] / 100.0).clip(0, 1)\n\nbaseline = df[\"priority_index\"].median()\ndf[\"priority_index_conf_adj\"] = (\n    df[\"confidence_0_1\"] * df[\"priority_index\"] + (1 - df[\"confidence_0_1\"]) * baseline\n)\n\n# Classification bands (plus hard overrides)\ndef band(score):\n    if score >= 85:\n        return \"Red\"\n    if score >= 70:\n        return \"Orange\"\n    if score >= 50:\n        return \"Yellow\"\n    return \"Green\"\n\n\ndf[\"priority_band\"] = df[\"priority_index_conf_adj\"].apply(band)\n\nhard_red = (df[\"nws_global_alert_score\"].fillna(0) >= 95) | (df[\"flood_hazard_muni\"].fillna(0) >= 90)\ndf.loc[hard_red, \"priority_band\"] = \"Red\"\n\ndf[\"phase\"] = phase\n\nout_cols = [\n    \"municipio\", \"municipio_key\", \"latitude\", \"longitude\",\n    \"hazard_combined\", \"flood_hazard_muni\", \"earthquake_hazard_score\",\n    \"exposure_score\", \"vulnerability_score\", \"resilience_index\",\n    \"response_readiness_index\", \"recovery_capacity_index\",\n    \"risk_index_raw\", \"priority_index\", \"priority_index_conf_adj\",\n    \"confidence_score\", \"confidence_0_1\", \"priority_band\", \"phase\"\n]\n\nscored = df[out_cols].sort_values([\"priority_index_conf_adj\", \"municipio\"], ascending=[False, True]).reset_index(drop=True)\nout_file = OUTPUT_DIR / \"municipio_indices_scored.csv\"\nscored.to_csv(out_file, index=False)\n\nprint(f\"Phase: {phase}\")\nprint(f\"Output: {out_file}\")\ndisplay(scored.head(15))\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}