{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 02 Ingest Earthquake Hazard Feeds (USGS)\n\nStage: `01_ingest_hazard`\nDiscipline: earthquake hazard data generation.\n\nOutputs:\n- `JupyterNotebooks/outputs/index_pipeline/01_ingest/usgs_earthquake_events.csv`\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Setup\nimport importlib.util\nimport subprocess\nimport sys\nimport logging\nimport os\nfrom datetime import datetime, timedelta, timezone\nfrom pathlib import Path\n\n\ndef ensure_packages(packages):\n    missing = [p for p in packages if importlib.util.find_spec(p) is None]\n    if missing:\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", *missing])\n\n\nensure_packages([\"pandas\", \"requests\"])\n\nimport pandas as pd\nimport requests\n\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\nlogger = logging.getLogger(\"index-pipeline-stage01-eq\")\n\n\ndef find_repo_root():\n    p = Path.cwd().resolve()\n    for c in [p, *p.parents]:\n        if (c / \"JupyterNotebooks\").exists():\n            return c\n    return p\n\n\nREPO_ROOT = find_repo_root()\nOUTPUT_DIR = REPO_ROOT / \"JupyterNotebooks\" / \"outputs\" / \"index_pipeline\" / \"01_ingest\"\nOUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n\ntry:\n    from IPython.display import display\nexcept ImportError:\n    display = print\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: Configuration\nLOOKBACK_DAYS = int(os.environ.get(\"EQ_LOOKBACK_DAYS\", \"30\"))\nMIN_MAG = float(os.environ.get(\"EQ_MIN_MAG\", \"1.0\"))\n\nPR_EXTENT = {\n    \"minlatitude\": 17.4,\n    \"maxlatitude\": 18.9,\n    \"minlongitude\": -68.6,\n    \"maxlongitude\": -65.0,\n}\n\nUSGS_EQ_URL = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\nRUN_UTC = datetime.now(timezone.utc)\nSTART_UTC = RUN_UTC - timedelta(days=LOOKBACK_DAYS)\n\nprint(f\"Lookback days: {LOOKBACK_DAYS} | Min magnitude: {MIN_MAG}\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: Fetch and export\nparams = {\n    \"format\": \"geojson\",\n    \"starttime\": START_UTC.strftime(\"%Y-%m-%d\"),\n    \"endtime\": RUN_UTC.strftime(\"%Y-%m-%d\"),\n    \"minmagnitude\": MIN_MAG,\n    **PR_EXTENT,\n    \"orderby\": \"time\",\n}\n\nresp = requests.get(USGS_EQ_URL, params=params, timeout=120)\nresp.raise_for_status()\npayload = resp.json()\n\nrows = []\nfor feat in payload.get(\"features\", []):\n    props = feat.get(\"properties\", {})\n    geom = feat.get(\"geometry\") or {}\n    coords = geom.get(\"coordinates\") or [None, None, None]\n    event_time = pd.to_datetime(props.get(\"time\"), unit=\"ms\", utc=True, errors=\"coerce\")\n\n    rows.append({\n        \"event_id\": feat.get(\"id\"),\n        \"time_utc\": event_time,\n        \"magnitude\": props.get(\"mag\"),\n        \"depth_km\": coords[2],\n        \"longitude\": coords[0],\n        \"latitude\": coords[1],\n        \"place\": props.get(\"place\"),\n        \"status\": props.get(\"status\"),\n        \"alert_level\": props.get(\"alert\"),\n        \"tsunami\": props.get(\"tsunami\"),\n        \"updated_utc\": pd.to_datetime(props.get(\"updated\"), unit=\"ms\", utc=True, errors=\"coerce\"),\n        \"run_utc\": RUN_UTC,\n    })\n\neq_df = pd.DataFrame(rows).sort_values(\"time_utc\", ascending=False).reset_index(drop=True)\n\neq_out = OUTPUT_DIR / \"usgs_earthquake_events.csv\"\neq_df.to_csv(eq_out, index=False)\n\nprint(f\"Earthquake rows: {len(eq_df)}\")\nprint(f\"Output: {eq_out}\")\ndisplay(eq_df.head(10))\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}