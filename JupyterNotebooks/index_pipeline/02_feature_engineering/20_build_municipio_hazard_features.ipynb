{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 20 Build Municipio Hazard Features\n\nStage: `02_feature_engineering`\nDiscipline: hazard feature fusion and station-to-municipio aggregation.\n\nDependencies:\n- `outputs/index_pipeline/01_ingest/flood_station_latest_features.csv`\n- `outputs/index_pipeline/01_ingest/nws_alerts_enriched.csv`\n- `outputs/index_pipeline/01_ingest/usgs_earthquake_events.csv`\n- `outputs/index_pipeline/10_features/municipio_exposure_vulnerability_features.csv`\n\nOutput:\n- `outputs/index_pipeline/20_features/municipio_hazard_features.csv`\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1: Setup\nimport importlib.util\nimport subprocess\nimport sys\nfrom pathlib import Path\nimport logging\nimport math\nfrom datetime import datetime, timezone\n\n\ndef ensure_packages(packages):\n    missing = [p for p in packages if importlib.util.find_spec(p) is None]\n    if missing:\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", *missing])\n\n\nensure_packages([\"pandas\", \"numpy\"])\n\nimport numpy as np\nimport pandas as pd\n\nlogging.basicConfig(level=logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s\")\nlogger = logging.getLogger(\"index-pipeline-stage20\")\n\n\ndef find_repo_root():\n    p = Path.cwd().resolve()\n    for c in [p, *p.parents]:\n        if (c / \"JupyterNotebooks\").exists():\n            return c\n    return p\n\n\nREPO_ROOT = find_repo_root()\nBASE_OUT = REPO_ROOT / \"JupyterNotebooks\" / \"outputs\" / \"index_pipeline\"\nINGEST_DIR = BASE_OUT / \"01_ingest\"\nFEATURES10_DIR = BASE_OUT / \"10_features\"\nOUTPUT_DIR = BASE_OUT / \"20_features\"\nOUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n\ntry:\n    from IPython.display import display\nexcept ImportError:\n    display = print\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 2: Load dependencies\nstation_file = INGEST_DIR / \"flood_station_latest_features.csv\"\nalerts_file = INGEST_DIR / \"nws_alerts_enriched.csv\"\neq_file = INGEST_DIR / \"usgs_earthquake_events.csv\"\nmuni_file = FEATURES10_DIR / \"municipio_exposure_vulnerability_features.csv\"\n\nfor f in [station_file, alerts_file, eq_file, muni_file]:\n    if not f.exists():\n        raise FileNotFoundError(f\"Missing dependency: {f}\")\n\nstation_df = pd.read_csv(station_file)\nalerts_df = pd.read_csv(alerts_file)\neq_df = pd.read_csv(eq_file)\nmuni_df = pd.read_csv(muni_file)\n\nstation_df[\"latest_time_utc\"] = pd.to_datetime(station_df[\"latest_time_utc\"], utc=True, errors=\"coerce\")\neq_df[\"time_utc\"] = pd.to_datetime(eq_df[\"time_utc\"], utc=True, errors=\"coerce\")\n\nprint(f\"Stations: {len(station_df)} | Alerts: {len(alerts_df)} | Earthquakes: {len(eq_df)} | Municipios: {len(muni_df)}\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cell 3: Build hazard features by municipio\nLAMBDA_KM = float(25.0)  # distance decay scale\nSTATION_OVERRIDE_KM = float(12.0)\n\n\ndef haversine_km(lat1, lon1, lat2, lon2):\n    r = 6371.0\n    p1 = math.radians(lat1)\n    p2 = math.radians(lat2)\n    dlat = math.radians(lat2 - lat1)\n    dlon = math.radians(lon2 - lon1)\n    a = math.sin(dlat / 2) ** 2 + math.cos(p1) * math.cos(p2) * math.sin(dlon / 2) ** 2\n    return 2 * r * math.asin(math.sqrt(a))\n\n\ndef robust_to_0_100(series):\n    x = pd.to_numeric(series, errors=\"coerce\")\n    lo = x.quantile(0.05)\n    hi = x.quantile(0.95)\n    if pd.isna(lo) or pd.isna(hi) or hi <= lo:\n        return pd.Series(np.nan, index=x.index)\n    return ((x - lo) / (hi - lo)).clip(0, 1) * 100\n\nnws_global_alert = float(alerts_df[\"alert_score\"].max()) if len(alerts_df) else 0.0\nrun_utc = datetime.now(timezone.utc)\n\nrows = []\nfor _, m in muni_df.iterrows():\n    mlat = pd.to_numeric(m.get(\"latitude\"), errors=\"coerce\")\n    mlon = pd.to_numeric(m.get(\"longitude\"), errors=\"coerce\")\n    if pd.isna(mlat) or pd.isna(mlon):\n        continue\n\n    sdf = station_df.copy()\n    sdf[\"dist_km\"] = sdf.apply(lambda r: haversine_km(mlat, mlon, float(r[\"lat\"]), float(r[\"lon\"])), axis=1)\n    sdf[\"w\"] = np.exp(-sdf[\"dist_km\"] / LAMBDA_KM)\n\n    weighted_flood = np.average(sdf[\"flood_hazard_final\"], weights=sdf[\"w\"]) if len(sdf) else np.nan\n\n    nearby = sdf[sdf[\"dist_km\"] <= STATION_OVERRIDE_KM]\n    local_max = nearby[\"flood_hazard_final\"].max() if len(nearby) else np.nan\n\n    flood_hazard_muni = np.nanmax([weighted_flood, local_max, nws_global_alert])\n\n    # Earthquake proxy: max event severity weighted by recency and depth\n    eq_local = eq_df.copy()\n    if len(eq_local):\n        eq_local[\"dist_km\"] = eq_local.apply(\n            lambda r: haversine_km(mlat, mlon, float(r[\"latitude\"]), float(r[\"longitude\"])), axis=1\n        )\n        eq_local[\"age_h\"] = (run_utc - eq_local[\"time_utc\"]).dt.total_seconds() / 3600.0\n        eq_local[\"depth_factor\"] = 1.0 / (1.0 + pd.to_numeric(eq_local[\"depth_km\"], errors=\"coerce\").fillna(0) / 70.0)\n        eq_local[\"recency_factor\"] = np.exp(-eq_local[\"age_h\"].clip(lower=0) / 168.0)\n        eq_local[\"intensity_raw\"] = (\n            pd.to_numeric(eq_local[\"magnitude\"], errors=\"coerce\").fillna(0)\n            / np.log1p(eq_local[\"dist_km\"].clip(lower=1e-3))\n            * eq_local[\"depth_factor\"]\n            * eq_local[\"recency_factor\"]\n        )\n        eq_raw = eq_local[\"intensity_raw\"].max()\n    else:\n        eq_raw = np.nan\n\n    rows.append({\n        \"municipio\": m[\"municipio\"],\n        \"municipio_key\": m[\"municipio_key\"],\n        \"latitude\": mlat,\n        \"longitude\": mlon,\n        \"flood_hazard_weighted\": weighted_flood,\n        \"flood_hazard_local_max\": local_max,\n        \"nws_global_alert_score\": nws_global_alert,\n        \"flood_hazard_muni\": flood_hazard_muni,\n        \"earthquake_raw\": eq_raw,\n        \"supporting_station_count\": len(sdf),\n        \"nearby_station_count\": int(len(nearby)),\n    })\n\nhaz_df = pd.DataFrame(rows)\nhaz_df[\"earthquake_hazard_score\"] = robust_to_0_100(haz_df[\"earthquake_raw\"]).fillna(0)\nhaz_df[\"hazard_combined\"] = haz_df[[\"flood_hazard_muni\", \"earthquake_hazard_score\"]].max(axis=1)\n\n# freshness proxy from latest noaa obs\nif len(station_df):\n    latest_obs = pd.to_datetime(station_df[\"latest_time_utc\"], utc=True, errors=\"coerce\").max()\nelse:\n    latest_obs = pd.NaT\nhaz_df[\"noaa_latest_obs_utc\"] = latest_obs\n\nout_file = OUTPUT_DIR / \"municipio_hazard_features.csv\"\nhaz_df.to_csv(out_file, index=False)\n\nprint(f\"Output: {out_file}\")\ndisplay(haz_df.head(10))\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}