{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed030305",
   "metadata": {},
   "source": [
    "# Puerto Rico Census Risk Features (Town, ZIP, Coordinates)\n",
    "\n",
    "This notebook pulls the latest available ACS 5-year Census data for Puerto Rico, builds risk features, and exports model-ready tables for municipios, ZIP Code Tabulation Areas (ZCTAs), and town coordinate points.\n",
    "\n",
    "Data sources in this notebook are public/open:\n",
    "- U.S. Census API (ACS 5-year)\n",
    "- U.S. Census Geocoder API (optional point-to-geography lookup)\n",
    "- Local PR town coordinate lookup file (`Puerto_RIco_Towns_Coords.xlsx`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ef6ce0",
   "metadata": {},
   "source": [
    "## Run Instructions\n",
    "\n",
    "1. Run cells top-to-bottom.\n",
    "2. Optional `.env` values:\n",
    "   - `CENSUS_API_KEY=<your_key>` (optional; useful above 500 requests/day/IP)\n",
    "   - `ACS_YEAR=2024` (optional; if omitted, notebook auto-detects latest available year)\n",
    "   - `PR_TOWNS_COORDS_FILE=JupyterNotebooks/Puerto_RIco_Towns_Coords.xlsx` (optional override)\n",
    "   - `ENABLE_CENSUS_GEOCODER=1` (optional; enriches town points with county/tract GEOIDs)\n",
    "3. Outputs are written to `JupyterNotebooks/outputs/census_pr/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bd4496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install and import dependencies\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "import unicodedata\n",
    "from datetime import datetime, UTC\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Installing required packages...\")\n",
    "required_packages = [\"pandas\", \"requests\", \"openpyxl\", \"python-dotenv\", \"numpy\"]\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", *required_packages])\n",
    "print(\"Installation complete.\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "try:\n",
    "    from IPython.display import display\n",
    "except ImportError:\n",
    "    display = print\n",
    "\n",
    "# Load .env if present in repo root or current directory\n",
    "load_dotenv(Path.cwd() / \".env\")\n",
    "load_dotenv(Path.cwd().parent / \".env\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_colwidth\", 120)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"census-pr-risk\")\n",
    "\n",
    "print(\"Cell 1 complete: dependencies installed and imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74050119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration and helper functions\n",
    "PR_STATE_FIPS = \"72\"\n",
    "ACS_DATASET = \"acs/acs5\"\n",
    "DEFAULT_TOWNS_FILE = \"Puerto_RIco_Towns_Coords.xlsx\"\n",
    "OUTPUT_DIR = Path(\"JupyterNotebooks/outputs/census_pr\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CENSUS_API_KEY = os.environ.get(\"CENSUS_API_KEY\")\n",
    "ACS_YEAR_ENV = os.environ.get(\"ACS_YEAR\", \"\").strip()\n",
    "ENABLE_CENSUS_GEOCODER = os.environ.get(\"ENABLE_CENSUS_GEOCODER\", \"\").lower() in {\"1\", \"true\", \"yes\"}\n",
    "\n",
    "ACS_VARIABLES = {\n",
    "    \"population\": \"B01003_001E\",\n",
    "    \"median_income\": \"B19013_001E\",\n",
    "    \"poverty_universe\": \"B17001_001E\",\n",
    "    \"poverty_count\": \"B17001_002E\",\n",
    "    \"housing_units\": \"B25001_001E\",\n",
    "    \"occupied_units\": \"B25002_002E\",\n",
    "    \"vacant_units\": \"B25002_003E\",\n",
    "    \"no_vehicle_owner\": \"B25044_003E\",\n",
    "    \"no_vehicle_renter\": \"B25044_010E\",\n",
    "}\n",
    "\n",
    "CENSUS_SENTINEL_MISSING = {\n",
    "    -666666666, -555555555, -333333333, -222222222, -111111111, -999999999\n",
    "}\n",
    "\n",
    "\n",
    "def resolve_file(filename, env_var=None, search_roots=None):\n",
    "    if env_var:\n",
    "        env_value = os.environ.get(env_var)\n",
    "        if env_value:\n",
    "            candidate = Path(env_value).expanduser()\n",
    "            if candidate.exists():\n",
    "                return candidate\n",
    "            raise FileNotFoundError(f\"{env_var} is set but file was not found: {candidate}\")\n",
    "\n",
    "    roots = search_roots or [Path.cwd(), Path.cwd() / \"JupyterNotebooks\", Path.cwd().parent]\n",
    "    for root in roots:\n",
    "        if not root.exists():\n",
    "            continue\n",
    "        found = next(root.rglob(filename), None)\n",
    "        if found:\n",
    "            return found\n",
    "    raise FileNotFoundError(f\"Could not find {filename}. Set {env_var} or place the file under this repo.\")\n",
    "\n",
    "\n",
    "def normalize_text(value):\n",
    "    if pd.isna(value):\n",
    "        return \"\"\n",
    "    text = str(value).strip()\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    text = \"\".join(ch for ch in text if not unicodedata.combining(ch))\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "\n",
    "def parse_zip_codes(value):\n",
    "    if pd.isna(value):\n",
    "        return []\n",
    "    return sorted(set(re.findall(r\"\\b\\d{5}\\b\", str(value))))\n",
    "\n",
    "\n",
    "def to_numeric(df, columns):\n",
    "    for col in columns:\n",
    "        numeric_series = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        df[col] = numeric_series.replace(list(CENSUS_SENTINEL_MISSING), np.nan)\n",
    "    return df\n",
    "\n",
    "\n",
    "def safe_divide(numerator, denominator):\n",
    "    result = numerator / denominator.replace({0: np.nan})\n",
    "    return result.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "\n",
    "def minmax_score(series, invert=False):\n",
    "    values = pd.to_numeric(series, errors=\"coerce\")\n",
    "    vmin = values.min(skipna=True)\n",
    "    vmax = values.max(skipna=True)\n",
    "    if pd.isna(vmin) or pd.isna(vmax) or vmin == vmax:\n",
    "        score = pd.Series(np.nan, index=values.index, dtype=\"float64\")\n",
    "    else:\n",
    "        score = (values - vmin) / (vmax - vmin)\n",
    "    if invert:\n",
    "        score = 1 - score\n",
    "    return score.clip(lower=0, upper=1)\n",
    "\n",
    "\n",
    "def find_latest_acs5_year(state_fips=\"72\", min_year=2010):\n",
    "    current_year = datetime.now(UTC).year\n",
    "    for year in range(current_year, min_year - 1, -1):\n",
    "        url = f\"https://api.census.gov/data/{year}/{ACS_DATASET}\"\n",
    "        params = {\"get\": \"NAME\", \"for\": f\"state:{state_fips}\"}\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=30)\n",
    "            if response.status_code == 200:\n",
    "                return year\n",
    "        except requests.RequestException:\n",
    "            continue\n",
    "    raise RuntimeError(\"Unable to find an available ACS 5-year dataset year.\")\n",
    "\n",
    "\n",
    "def census_get(year, variables, geography_params, api_key=None):\n",
    "    url = f\"https://api.census.gov/data/{year}/{ACS_DATASET}\"\n",
    "    params = {\"get\": \",\".join(variables)}\n",
    "    params.update(geography_params)\n",
    "    if api_key:\n",
    "        params[\"key\"] = api_key\n",
    "\n",
    "    response = requests.get(url, params=params, timeout=90)\n",
    "    try:\n",
    "        response.raise_for_status()\n",
    "    except requests.HTTPError as exc:\n",
    "        raise RuntimeError(f\"Census API error for {url}: {response.text}\") from exc\n",
    "\n",
    "    payload = response.json()\n",
    "    return pd.DataFrame(payload[1:], columns=payload[0])\n",
    "\n",
    "\n",
    "def geocode_coordinates(lat, lon):\n",
    "    url = \"https://geocoding.geo.census.gov/geocoder/geographies/coordinates\"\n",
    "    params = {\n",
    "        \"x\": lon,\n",
    "        \"y\": lat,\n",
    "        \"benchmark\": \"Public_AR_Current\",\n",
    "        \"vintage\": \"Current_Current\",\n",
    "        \"format\": \"json\",\n",
    "    }\n",
    "    response = requests.get(url, params=params, timeout=30)\n",
    "    response.raise_for_status()\n",
    "    result = response.json().get(\"result\", {}).get(\"geographies\", {})\n",
    "\n",
    "    county_info = (result.get(\"Counties\") or [{}])[0]\n",
    "    tract_info = (result.get(\"Census Tracts\") or [{}])[0]\n",
    "\n",
    "    return {\n",
    "        \"county_geoid\": county_info.get(\"GEOID\"),\n",
    "        \"county_name\": county_info.get(\"NAME\"),\n",
    "        \"tract_geoid\": tract_info.get(\"GEOID\"),\n",
    "        \"tract_name\": tract_info.get(\"NAME\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def choose_acs_year():\n",
    "    if ACS_YEAR_ENV:\n",
    "        try:\n",
    "            return int(ACS_YEAR_ENV)\n",
    "        except ValueError as exc:\n",
    "            raise ValueError(\"ACS_YEAR must be an integer like 2024\") from exc\n",
    "    return find_latest_acs5_year(state_fips=PR_STATE_FIPS)\n",
    "\n",
    "\n",
    "selected_year = choose_acs_year()\n",
    "print(f\"ACS year selected: {selected_year}\")\n",
    "print(f\"Census API key provided: {'yes' if CENSUS_API_KEY else 'no'}\")\n",
    "print(f\"Census geocoder enabled: {ENABLE_CENSUS_GEOCODER}\")\n",
    "print(\"Cell 2 complete: config and helpers ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a136d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Pull ACS data for PR municipios and ZCTAs\n",
    "requested_columns = [\"NAME\", *ACS_VARIABLES.values()]\n",
    "rename_map = {v: k for k, v in ACS_VARIABLES.items()}\n",
    "\n",
    "# Municipio-level data (Census county geography for Puerto Rico)\n",
    "municipio_df = census_get(\n",
    "    year=selected_year,\n",
    "    variables=requested_columns,\n",
    "    geography_params={\"for\": \"county:*\", \"in\": f\"state:{PR_STATE_FIPS}\"},\n",
    "    api_key=CENSUS_API_KEY,\n",
    ")\n",
    "municipio_df = municipio_df.rename(columns=rename_map)\n",
    "municipio_df = to_numeric(municipio_df, list(ACS_VARIABLES.keys()))\n",
    "municipio_df[\"municipio\"] = (\n",
    "    municipio_df[\"NAME\"]\n",
    "    .str.replace(\", Puerto Rico\", \"\", regex=False)\n",
    "    .str.replace(\" Municipio\", \"\", regex=False)\n",
    ")\n",
    "municipio_df[\"municipio_key\"] = municipio_df[\"municipio\"].map(normalize_text)\n",
    "\n",
    "# ZCTA data is queried nationally, then filtered to PR ZIP codes from local town table\n",
    "zcta_df = census_get(\n",
    "    year=selected_year,\n",
    "    variables=requested_columns,\n",
    "    geography_params={\"for\": \"zip code tabulation area:*\"},\n",
    "    api_key=CENSUS_API_KEY,\n",
    ")\n",
    "zcta_rename = rename_map.copy()\n",
    "zcta_rename[\"zip code tabulation area\"] = \"zip_code\"\n",
    "zcta_df = zcta_df.rename(columns=zcta_rename)\n",
    "zcta_df = to_numeric(zcta_df, list(ACS_VARIABLES.keys()))\n",
    "\n",
    "# Load local town lookup\n",
    "pr_towns_file = resolve_file(DEFAULT_TOWNS_FILE, env_var=\"PR_TOWNS_COORDS_FILE\")\n",
    "pr_towns_df = pd.read_excel(pr_towns_file)\n",
    "if \"municipio2\" in pr_towns_df.columns:\n",
    "    pr_towns_df[\"municipio\"] = pr_towns_df[\"municipio2\"].fillna(pr_towns_df.get(\"municipio\"))\n",
    "elif \"municipio\" not in pr_towns_df.columns:\n",
    "    raise ValueError(\"Town lookup file must include municipio or municipio2 column.\")\n",
    "\n",
    "for col in [\"latitude\", \"longitude\"]:\n",
    "    if col in pr_towns_df.columns:\n",
    "        pr_towns_df[col] = pd.to_numeric(pr_towns_df[col], errors=\"coerce\")\n",
    "\n",
    "if \"Zip Codes\" not in pr_towns_df.columns:\n",
    "    raise ValueError(\"Town lookup file must include 'Zip Codes' column.\")\n",
    "\n",
    "pr_towns_df[\"municipio_key\"] = pr_towns_df[\"municipio\"].map(normalize_text)\n",
    "pr_towns_df[\"zip_list\"] = pr_towns_df[\"Zip Codes\"].map(parse_zip_codes)\n",
    "pr_zip_set = {zip_code for zip_list in pr_towns_df[\"zip_list\"] for zip_code in zip_list}\n",
    "\n",
    "zcta_pr_df = zcta_df[zcta_df[\"zip_code\"].isin(pr_zip_set)].copy()\n",
    "\n",
    "print(f\"Municipios pulled: {len(municipio_df)}\")\n",
    "print(f\"US ZCTAs pulled: {len(zcta_df)}\")\n",
    "print(f\"PR ZCTAs retained after filter: {len(zcta_pr_df)}\")\n",
    "print(f\"Unique PR ZIP codes from lookup: {len(pr_zip_set)}\")\n",
    "\n",
    "print(\"\\nMunicipio sample:\")\n",
    "display(municipio_df.head(3))\n",
    "print(\"\\nZCTA sample:\")\n",
    "display(zcta_pr_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32bb4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Build risk features and baseline risk indexes\n",
    "\n",
    "def add_risk_features(df):\n",
    "    out = df.copy()\n",
    "\n",
    "    out[\"poverty_rate\"] = safe_divide(out[\"poverty_count\"], out[\"poverty_universe\"])\n",
    "    out[\"no_vehicle_rate\"] = safe_divide(\n",
    "        out[\"no_vehicle_owner\"] + out[\"no_vehicle_renter\"],\n",
    "        out[\"occupied_units\"],\n",
    "    )\n",
    "    out[\"vacancy_rate\"] = safe_divide(out[\"vacant_units\"], out[\"housing_units\"])\n",
    "\n",
    "    out[\"score_population\"] = minmax_score(out[\"population\"])\n",
    "    out[\"score_poverty\"] = minmax_score(out[\"poverty_rate\"])\n",
    "    out[\"score_income_vulnerability\"] = minmax_score(out[\"median_income\"], invert=True)\n",
    "    out[\"score_transport_vulnerability\"] = minmax_score(out[\"no_vehicle_rate\"])\n",
    "    out[\"score_housing_vulnerability\"] = minmax_score(out[\"vacancy_rate\"])\n",
    "\n",
    "    # Weighted baseline index (0-100). Adjust weights as your model evolves.\n",
    "    out[\"risk_index_raw\"] = (\n",
    "        0.30 * out[\"score_population\"].fillna(0)\n",
    "        + 0.25 * out[\"score_poverty\"].fillna(0)\n",
    "        + 0.20 * out[\"score_income_vulnerability\"].fillna(0)\n",
    "        + 0.15 * out[\"score_transport_vulnerability\"].fillna(0)\n",
    "        + 0.10 * out[\"score_housing_vulnerability\"].fillna(0)\n",
    "    )\n",
    "    out[\"risk_index\"] = (out[\"risk_index_raw\"] * 100).round(1)\n",
    "    return out\n",
    "\n",
    "\n",
    "municipio_risk_df = add_risk_features(municipio_df)\n",
    "zcta_risk_df = add_risk_features(zcta_pr_df)\n",
    "\n",
    "print(\"Top municipio risk rows:\")\n",
    "display(\n",
    "    municipio_risk_df[[\n",
    "        \"municipio\", \"population\", \"median_income\", \"poverty_rate\", \"no_vehicle_rate\", \"risk_index\"\n",
    "    ]]\n",
    "    .sort_values(\"risk_index\", ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(\"Top ZCTA risk rows:\")\n",
    "display(\n",
    "    zcta_risk_df[[\n",
    "        \"zip_code\", \"population\", \"median_income\", \"poverty_rate\", \"no_vehicle_rate\", \"risk_index\"\n",
    "    ]]\n",
    "    .sort_values(\"risk_index\", ascending=False)\n",
    "    .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cece5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Join municipio + ZIP features to town coordinates (model-ready table)\n",
    "\n",
    "towns_exploded_df = (\n",
    "    pr_towns_df[[\"designated_area\", \"municipio\", \"municipio_key\", \"latitude\", \"longitude\", \"zip_list\"]]\n",
    "    .explode(\"zip_list\")\n",
    "    .rename(columns={\"zip_list\": \"zip_code\"})\n",
    ")\n",
    "\n",
    "zip_feature_cols = [\n",
    "    \"zip_code\", \"risk_index\", \"population\", \"median_income\", \"poverty_rate\", \"no_vehicle_rate\", \"vacancy_rate\"\n",
    "]\n",
    "zip_aggregated_df = (\n",
    "    towns_exploded_df\n",
    "    .merge(zcta_risk_df[zip_feature_cols], on=\"zip_code\", how=\"left\")\n",
    "    .groupby([\"designated_area\", \"municipio\", \"municipio_key\", \"latitude\", \"longitude\"], dropna=False)\n",
    "    .agg(\n",
    "        zip_count=(\"zip_code\", \"nunique\"),\n",
    "        zip_risk_index=(\"risk_index\", \"mean\"),\n",
    "        zip_population=(\"population\", \"sum\"),\n",
    "        zip_median_income=(\"median_income\", \"mean\"),\n",
    "        zip_poverty_rate=(\"poverty_rate\", \"mean\"),\n",
    "        zip_no_vehicle_rate=(\"no_vehicle_rate\", \"mean\"),\n",
    "        zip_vacancy_rate=(\"vacancy_rate\", \"mean\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "municipio_feature_cols = [\n",
    "    \"municipio_key\", \"risk_index\", \"population\", \"median_income\", \"poverty_rate\", \"no_vehicle_rate\", \"vacancy_rate\"\n",
    "]\n",
    "town_risk_df = zip_aggregated_df.merge(\n",
    "    municipio_risk_df[municipio_feature_cols].rename(\n",
    "        columns={\n",
    "            \"risk_index\": \"municipio_risk_index\",\n",
    "            \"population\": \"municipio_population\",\n",
    "            \"median_income\": \"municipio_median_income\",\n",
    "            \"poverty_rate\": \"municipio_poverty_rate\",\n",
    "            \"no_vehicle_rate\": \"municipio_no_vehicle_rate\",\n",
    "            \"vacancy_rate\": \"municipio_vacancy_rate\",\n",
    "        }\n",
    "    ),\n",
    "    on=\"municipio_key\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "\n",
    "def blend_risk(municipio_risk, zip_risk):\n",
    "    if pd.notna(municipio_risk) and pd.notna(zip_risk):\n",
    "        return round(0.6 * municipio_risk + 0.4 * zip_risk, 1)\n",
    "    if pd.notna(municipio_risk):\n",
    "        return round(municipio_risk, 1)\n",
    "    if pd.notna(zip_risk):\n",
    "        return round(zip_risk, 1)\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "town_risk_df[\"risk_index\"] = town_risk_df.apply(\n",
    "    lambda row: blend_risk(row[\"municipio_risk_index\"], row[\"zip_risk_index\"]),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Optional: enrich points with county/tract GEOIDs for coordinate-based joins\n",
    "if ENABLE_CENSUS_GEOCODER:\n",
    "    geocoded_records = []\n",
    "    for row in town_risk_df.itertuples(index=False):\n",
    "        if pd.notna(row.latitude) and pd.notna(row.longitude):\n",
    "            try:\n",
    "                geocoded_records.append(geocode_coordinates(row.latitude, row.longitude))\n",
    "            except Exception as exc:\n",
    "                logger.warning(\"Geocoder failed for %s: %s\", row.designated_area, exc)\n",
    "                geocoded_records.append({\n",
    "                    \"county_geoid\": None,\n",
    "                    \"county_name\": None,\n",
    "                    \"tract_geoid\": None,\n",
    "                    \"tract_name\": None,\n",
    "                })\n",
    "        else:\n",
    "            geocoded_records.append({\n",
    "                \"county_geoid\": None,\n",
    "                \"county_name\": None,\n",
    "                \"tract_geoid\": None,\n",
    "                \"tract_name\": None,\n",
    "            })\n",
    "\n",
    "    geocoded_df = pd.DataFrame(geocoded_records)\n",
    "    town_risk_df = pd.concat([town_risk_df.reset_index(drop=True), geocoded_df], axis=1)\n",
    "\n",
    "print(\"Town-level sample:\")\n",
    "display(\n",
    "    town_risk_df[[\n",
    "        \"designated_area\", \"municipio\", \"latitude\", \"longitude\", \"risk_index\",\n",
    "        \"municipio_risk_index\", \"zip_risk_index\", \"zip_count\"\n",
    "    ]].head(10)\n",
    ")\n",
    "\n",
    "print(f\"Town rows generated: {len(town_risk_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51029638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Export CSV + GeoJSON outputs\n",
    "municipio_out = OUTPUT_DIR / \"municipio_risk_features.csv\"\n",
    "zcta_out = OUTPUT_DIR / \"zcta_risk_features.csv\"\n",
    "town_out = OUTPUT_DIR / \"town_risk_features.csv\"\n",
    "geojson_out = OUTPUT_DIR / \"town_risk_features.geojson\"\n",
    "\n",
    "municipio_risk_df.to_csv(municipio_out, index=False)\n",
    "zcta_risk_df.to_csv(zcta_out, index=False)\n",
    "town_risk_df.to_csv(town_out, index=False)\n",
    "\n",
    "geojson_features = []\n",
    "for row in town_risk_df.to_dict(orient=\"records\"):\n",
    "    lat = row.get(\"latitude\")\n",
    "    lon = row.get(\"longitude\")\n",
    "    if pd.isna(lat) or pd.isna(lon):\n",
    "        continue\n",
    "\n",
    "    attrs = {}\n",
    "    for key, value in row.items():\n",
    "        if pd.isna(value):\n",
    "            attrs[key] = None\n",
    "        elif isinstance(value, (np.integer, np.floating)):\n",
    "            attrs[key] = value.item()\n",
    "        else:\n",
    "            attrs[key] = value\n",
    "\n",
    "    geojson_features.append(\n",
    "        {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\"type\": \"Point\", \"coordinates\": [float(lon), float(lat)]},\n",
    "            \"properties\": attrs,\n",
    "        }\n",
    "    )\n",
    "\n",
    "geojson_payload = {\"type\": \"FeatureCollection\", \"features\": geojson_features}\n",
    "with open(geojson_out, \"w\", encoding=\"utf-8\") as file_handle:\n",
    "    json.dump(geojson_payload, file_handle, ensure_ascii=False, indent=2, default=str)\n",
    "\n",
    "print(\"Export complete:\")\n",
    "print(f\"- {municipio_out}\")\n",
    "print(f\"- {zcta_out}\")\n",
    "print(f\"- {town_out}\")\n",
    "print(f\"- {geojson_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f06ff6",
   "metadata": {},
   "source": [
    "## Next Modeling Steps\n",
    "\n",
    "- Add hazard intensity features from your USGS/NOAA/USACE notebooks (flood stage, alert density, event frequency).\n",
    "- Use this notebook output as static/demographic vulnerability features.\n",
    "- Train and compare candidate models (e.g., linear baseline, random forest, gradient boosting) on a shared event-labeled dataset.\n",
    "- Keep all secrets in `.env` only; do not hardcode keys in notebooks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
