{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to your notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell to connect to your GIS and get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ArcGIS connection is handled in the main cell (USE_ARCGIS).\n",
    "# This cell is intentionally left blank for local runs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now you are ready to start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%\n",
    "# \"\"\"\n",
    "# USGS ‚Üí AGOL Sync Notebook üåé‚û°Ô∏èüó∫Ô∏è  (v2 ‚Äì NaN‚Äësafe)\n",
    "# =================================================\n",
    "# Fixes the *TypeError: JSON object must be str ‚Ä¶ not float* when the\n",
    "# `Parameters_or_Selectors` cell is blank (Excel reads it as NaN/float).\n",
    "\n",
    "# Key change ‚Üí robust JSON parse:\n",
    "# ```python\n",
    "# params_raw = row.get(\"Parameters_or_Selectors\")\n",
    "# if isinstance(params_raw, str) and params_raw.strip():\n",
    "#     jparams = json.loads(params_raw)\n",
    "# else:\n",
    "#     jparams = {}\n",
    "# ```\n",
    "# Everything else unchanged (field names already aligned).\n",
    "\n",
    "# Optional: ArcGIS Online Sync\n",
    "# To publish updates to ArcGIS Online, set:\n",
    "#   USE_ARCGIS=1\n",
    "#   USGS_EARTHQUAKE_LAYER_ID (or FEATURE_LAYER_ITEM_ID)\n",
    "# Then re-run the notebook from the top.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Imports\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import requests, json, logging, sys, math, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set USE_ARCGIS=1 to enable ArcGIS Online sync; otherwise run locally.\n",
    "USE_ARCGIS = os.environ.get(\"USE_ARCGIS\", \"\").lower() in (\"1\", \"true\", \"yes\")\n",
    "\n",
    "if USE_ARCGIS:\n",
    "    from arcgis.gis import GIS\n",
    "    from arcgis.features import Feature\n",
    "    from arcgis.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ----------------------------------------------------------------------\n",
    "# 1. CONFIG\n",
    "# ---------------------------------------------------------------------------\n",
    "def resolve_file(filename, env_var=None, search_roots=None):\n",
    "    if env_var:\n",
    "        env_val = os.environ.get(env_var)\n",
    "        if env_val:\n",
    "            return env_val\n",
    "    roots = search_roots or [Path.cwd(), Path.cwd().parent, Path.home()]\n",
    "    arcgis_home = Path(\"/arcgis/home\")\n",
    "    if arcgis_home.exists():\n",
    "        roots.append(arcgis_home)\n",
    "    for root in roots:\n",
    "        if root.exists():\n",
    "            match = next(root.rglob(filename), None)\n",
    "            if match:\n",
    "                return str(match)\n",
    "    raise FileNotFoundError(\"Set the required env var or place the file under the repo or /arcgis/home.\")\n",
    "\n",
    "EXCEL_PATH            = resolve_file(\"PR Alert Data Sources.xlsx\", env_var=\"PR_ALERT_XLSX\")\n",
    "FEATURE_LAYER_ITEM_ID = os.environ.get(\"USGS_EARTHQUAKE_LAYER_ID\") or os.environ.get(\"FEATURE_LAYER_ITEM_ID\")\n",
    "LAYER_INDEX           = 0\n",
    "SOURCE_URL_KEYWORD    = \"earthquake.usgs.gov\"\n",
    "\n",
    "if USE_ARCGIS and not FEATURE_LAYER_ITEM_ID:\n",
    "    raise ValueError(\"Set USGS_EARTHQUAKE_LAYER_ID (or FEATURE_LAYER_ITEM_ID) in the environment.\")\n",
    "\n",
    "# Local outputs (for non-ArcGIS runs)\n",
    "OUTPUT_DIR = Path(os.environ.get(\"OUTPUT_DIR\", \"outputs\"))\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_CSV = OUTPUT_DIR / \"usgs_earthquakes.csv\"\n",
    "OUTPUT_GEOJSON = OUTPUT_DIR / \"usgs_earthquakes.geojson\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\", stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ----------------------------------------------------------------------\n",
    "# 2. CONNECT to AGOL (optional)\n",
    "# ---------------------------------------------------------------------------\n",
    "if USE_ARCGIS:\n",
    "    logging.info(\"Connecting to ArcGIS Online‚Ä¶\")\n",
    "    try:\n",
    "        gis = GIS(\"home\")\n",
    "        logging.info(\"Connected to %s\", gis.properties.portalHostname)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"FATAL: Could not connect to ArcGIS Online. {e}\")\n",
    "        sys.exit(1)\n",
    "else:\n",
    "    gis = None\n",
    "    logging.info(\"ArcGIS disabled; running locally only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ----------------------------------------------------------------------\n",
    "# 3. READ Excel & extract parameters\n",
    "# ---------------------------------------------------------------------------\n",
    "logging.info(\"Reading master Excel file: %s\", Path(EXCEL_PATH).name)\n",
    "cfg = pd.read_excel(EXCEL_PATH)\n",
    "row_sel = cfg[cfg[\"URL_Endpoint\"].str.contains(SOURCE_URL_KEYWORD, case=False, na=False)].head(1)\n",
    "if row_sel.empty:\n",
    "    raise ValueError(f\"No row with URL_Endpoint containing '{SOURCE_URL_KEYWORD}' found.\")\n",
    "row = row_sel.iloc[0]\n",
    "\n",
    "# --- Robust JSON parse (handles NaN) --------------------------------------\n",
    "params_raw = row.get(\"Parameters_or_Selectors\")\n",
    "if isinstance(params_raw, str) and params_raw.strip():\n",
    "    try:\n",
    "        jparams = json.loads(params_raw)\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Parameters_or_Selectors JSON malformed: {e}\")\n",
    "else:\n",
    "    jparams = {}\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "days_back = int(jparams.get(\"days_back\", 7))\n",
    "min_mag   = jparams.get(\"min_magnitude\")\n",
    "max_mag   = jparams.get(\"max_magnitude\")\n",
    "bbox_raw  = row.get(\"Bounding_Box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ----------------------------------------------------------------------\n",
    "# 4. BUILD USGS query & fetch\n",
    "# ---------------------------------------------------------------------------\n",
    "end_date   = datetime.now(timezone.utc)\n",
    "start_date = end_date - timedelta(days=days_back)\n",
    "query = {\n",
    "    \"format\": \"geojson\",\n",
    "    \"starttime\": start_date.strftime(\"%Y-%m-%d\"),\n",
    "    \"endtime\":   end_date.strftime(\"%Y-%m-%d\")\n",
    "}\n",
    "if pd.notna(min_mag): query[\"minmagnitude\"] = float(min_mag)\n",
    "if pd.notna(max_mag): query[\"maxmagnitude\"] = float(max_mag)\n",
    "if isinstance(bbox_raw, str) and bbox_raw.strip():\n",
    "    try:\n",
    "        min_lon, min_lat, max_lon, max_lat = [float(x) for x in bbox_raw.split(',')]\n",
    "        query.update({\"minlongitude\": min_lon, \"minlatitude\": min_lat,\n",
    "                      \"maxlongitude\": max_lon, \"maxlatitude\": max_lat})\n",
    "    except ValueError:\n",
    "        logging.warning(\"Bounding_Box malformed ‚Äì ignoring spatial filter.\")\n",
    "\n",
    "USGS_ENDPOINT = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "logging.info(\"Requesting USGS data (%d‚Äëday window)‚Ä¶\", days_back)\n",
    "resp = requests.get(USGS_ENDPOINT, params=query, timeout=30)\n",
    "resp.raise_for_status()\n",
    "features = resp.json().get(\"features\", [])\n",
    "logging.info(\"Retrieved %d events\", len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% ----------------------------------------------------------------------\n",
    "# 5. TO DATAFRAME (with correct column names)\n",
    "# ---------------------------------------------------------------------------\n",
    "records = []\n",
    "for f in features:\n",
    "    p, g = f.get(\"properties\", {}), f.get(\"geometry\", {})\n",
    "    coords = g.get(\"coordinates\", [None, None, None])\n",
    "    records.append({\n",
    "        \"time\":            pd.to_datetime(p.get(\"time\"), unit=\"ms\", errors=\"coerce\", utc=True),\n",
    "        \"place\":           p.get(\"place\"),\n",
    "        \"magnitude\":       p.get(\"mag\"),\n",
    "        \"depth_km\":        coords[2],\n",
    "        \"tsunami_warning\": p.get(\"tsunami\"),\n",
    "        \"status\":          p.get(\"status\"),\n",
    "        \"alert_level\":     p.get(\"alert\"),\n",
    "        \"longitude\":       coords[0],\n",
    "        \"latitude\":        coords[1]\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "logging.info(\"DataFrame ready (%d rows)\", len(df))\n",
    "\n",
    "if not USE_ARCGIS:\n",
    "    if df.empty:\n",
    "        logging.info(\"No records to write locally.\")\n",
    "    else:\n",
    "        df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "        def to_jsonable(val):\n",
    "            if isinstance(val, pd.Timestamp):\n",
    "                return val.isoformat()\n",
    "            try:\n",
    "                if pd.isna(val):\n",
    "                    return None\n",
    "            except Exception:\n",
    "                pass\n",
    "            if hasattr(val, \"item\"):\n",
    "                try:\n",
    "                    return val.item()\n",
    "                except Exception:\n",
    "                    pass\n",
    "            return val\n",
    "\n",
    "        features = []\n",
    "        if {\"longitude\", \"latitude\"}.issubset(df.columns):\n",
    "            for _, row in df.iterrows():\n",
    "                lon = row.get(\"longitude\")\n",
    "                lat = row.get(\"latitude\")\n",
    "                if pd.notna(lon) and pd.notna(lat):\n",
    "                    props = row.drop(labels=[\"longitude\", \"latitude\"]).to_dict()\n",
    "                    props = {k: to_jsonable(v) for k, v in props.items()}\n",
    "                    features.append({\n",
    "                        \"type\": \"Feature\",\n",
    "                        \"geometry\": {\"type\": \"Point\", \"coordinates\": [float(lon), float(lat)]},\n",
    "                        \"properties\": props\n",
    "                    })\n",
    "        geojson = {\"type\": \"FeatureCollection\", \"features\": features}\n",
    "        with open(OUTPUT_GEOJSON, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(geojson, f, ensure_ascii=False, indent=2)\n",
    "        logging.info(\"Local outputs written: %s and %s\", OUTPUT_CSV, OUTPUT_GEOJSON)\n",
    "\n",
    "# %% ----------------------------------------------------------------------\n",
    "if USE_ARCGIS:\n",
    "    # 6. ACCESS / TRUNCATE FEATURE LAYER\n",
    "    # ---------------------------------------------------------------------------\n",
    "    flayer = gis.content.get(FEATURE_LAYER_ITEM_ID).layers[LAYER_INDEX]\n",
    "    logging.info(\"Target layer: %s\", flayer.properties.name)\n",
    "    if flayer.query(return_count_only=True):\n",
    "        logging.info(\"Truncating existing features‚Ä¶\")\n",
    "        flayer.delete_features(where=\"1=1\")\n",
    "\n",
    "    # %% ----------------------------------------------------------------------\n",
    "    # 7. PREP & PUSH ADDS\n",
    "    # ---------------------------------------------------------------------------\n",
    "    adds = []\n",
    "    has_geom = bool(getattr(flayer.properties, \"geometryType\", \"\"))\n",
    "\n",
    "    for _, r in df.iterrows():\n",
    "        attrs = {\n",
    "            \"time\":            int(r[\"time\"].timestamp()*1000) if pd.notna(r[\"time\"]) else None,\n",
    "            \"place\":           r[\"place\"],\n",
    "            \"magnitude\":       float(r[\"magnitude\"]) if pd.notna(r[\"magnitude\"]) else None,\n",
    "            \"depth_km\":        float(r[\"depth_km\"]) if pd.notna(r[\"depth_km\"]) else None,\n",
    "            \"tsunami_warning\": int(r[\"tsunami_warning\"]) if pd.notna(r[\"tsunami_warning\"]) else None,\n",
    "            \"status\":          r[\"status\"],\n",
    "            \"alert_level\":     r[\"alert_level\"],\n",
    "            \"longitude\":       float(r[\"longitude\"]) if pd.notna(r[\"longitude\"]) else None,\n",
    "            \"latitude\":        float(r[\"latitude\"]) if pd.notna(r[\"latitude\"]) else None,\n",
    "        }\n",
    "\n",
    "        geom = None\n",
    "        if has_geom and pd.notna(r[\"longitude\"]) and pd.notna(r[\"latitude\"]):\n",
    "            geom = Point({\"x\": r[\"longitude\"], \"y\": r[\"latitude\"], \"spatialReference\": {\"wkid\": 4326}})\n",
    "\n",
    "        adds.append(Feature(geometry=geom, attributes=attrs))\n",
    "\n",
    "    if adds:\n",
    "        res = flayer.edit_features(adds=adds, rollback_on_failure=True)\n",
    "        if all(r.get(\"success\") for r in res.get(\"addResults\", [])):\n",
    "            logging.info(\"‚úî Added %d features to layer\", len(adds))\n",
    "        else:\n",
    "            logging.error(\"Some features failed to add ‚Äì check layer for details.\")\n",
    "    else:\n",
    "        logging.warning(\"No features to add (empty DataFrame)\")\n",
    "\n",
    "    logging.info(\"üî• Workflow complete ‚Äì layer refreshed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "esriNotebookRuntime": {
   "notebookRuntimeName": "ArcGIS Notebook Python 3 Standard",
   "notebookRuntimeVersion": "12.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
